
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://zhang-each.github.io/My-CS-notebook/CS231N/Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B04%EF%BC%9A%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN/">
      
      
        <link rel="prev" href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B03%EF%BC%9ANormalization%E5%92%8CDropOut/">
      
      
        <link rel="next" href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B05%EF%BC%9ARNN%26LSTM%E4%B8%8E%E5%9B%BE%E7%89%87%E6%8F%8F%E8%BF%B0/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.6">
    
    
      
        <title>04.卷积神经网络CNN - 小角龙的学习记录</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.558e4712.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Hiragino+Sans+GB:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Hiragino Sans GB";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../css/timeago.css">
    
      <link rel="stylesheet" href="../../from_oi_wiki/css/extra.css?v=13">
    
      <link rel="stylesheet" href="../../css/status.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#stanford-cs231n-assignment札记4卷积神经网络cnn" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="小角龙的学习记录" class="md-header__button md-logo" aria-label="小角龙的学习记录" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            小角龙的学习记录
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              04.卷积神经网络CNN
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/zhang-each/My-CS-notebook/" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Zhang-Each/My-CS-notebook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        🏡 主页
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../" class="md-tabs__link md-tabs__link--active">
        🐰 深度学习
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../%E6%9D%82%E8%B0%88%E4%B8%8E%E6%80%BB%E7%BB%93/" class="md-tabs__link">
        杂谈与总结
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="小角龙的学习记录" class="md-nav__button md-logo" aria-label="小角龙的学习记录" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    小角龙的学习记录
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/zhang-each/My-CS-notebook/" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    Zhang-Each/My-CS-notebook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
        
          
            
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../..">🏡 主页</a>
          
        </div>
      
      <nav class="md-nav" aria-label="🏡 主页" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          🏡 主页
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../">🐰 深度学习</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="🐰 深度学习" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          🐰 深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" checked>
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2_2" tabindex="0" aria-expanded="true">
          CS231N-神经网络与深度学习
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="CS231N-神经网络与深度学习" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          CS231N-神经网络与深度学习
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B01%EF%BC%9AkNN%E5%92%8C%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/" class="md-nav__link">
        01.kNN和线性分类器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B02%EF%BC%9A%E5%A4%9A%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8/" class="md-nav__link">
        02.多层全连接神经网络和优化器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B03%EF%BC%9ANormalization%E5%92%8CDropOut/" class="md-nav__link">
        03.Normalization和DropOut
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          04.卷积神经网络CNN
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        04.卷积神经网络CNN
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#卷基层convolution-layer" class="md-nav__link">
    卷基层Convolution Layer
  </a>
  
    <nav class="md-nav" aria-label="卷基层Convolution Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#什么是卷积层" class="md-nav__link">
    什么是卷积层？
  </a>
  
    <nav class="md-nav" aria-label="什么是卷积层？">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#卷积的计算公式" class="md-nav__link">
    卷积的计算公式
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#步长stride" class="md-nav__link">
    步长Stride
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#接受域receptive-field" class="md-nav__link">
    接受域Receptive Field
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#padding操作" class="md-nav__link">
    Padding操作
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积层带来的突破" class="md-nav__link">
    卷积层带来的突破
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积层的代码实现" class="md-nav__link">
    卷积层的代码实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积层的反向传播" class="md-nav__link">
    卷积层的反向传播
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积的实际效果" class="md-nav__link">
    卷积的实际效果
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#池化层pooling-layer" class="md-nav__link">
    池化层Pooling Layer
  </a>
  
    <nav class="md-nav" aria-label="池化层Pooling Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#什么是池化层" class="md-nav__link">
    什么是池化层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#池化层的前向传播" class="md-nav__link">
    池化层的前向传播
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#池化层的反向传播" class="md-nav__link">
    池化层的反向传播
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#三层cnn" class="md-nav__link">
    三层CNN
  </a>
  
    <nav class="md-nav" aria-label="三层CNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#三层cnn的架构" class="md-nav__link">
    三层CNN的架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#代码实现" class="md-nav__link">
    代码实现
  </a>
  
    <nav class="md-nav" aria-label="代码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#初始化" class="md-nav__link">
    初始化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#前向传播和反向传播" class="md-nav__link">
    前向传播和反向传播
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#三层cnn的pytorch实现" class="md-nav__link">
    三层CNN的Pytorch实现
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B05%EF%BC%9ARNN%26LSTM%E4%B8%8E%E5%9B%BE%E7%89%87%E6%8F%8F%E8%BF%B0/" class="md-nav__link">
        05.RNN&LSTM与图片描述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B06%EF%BC%9ATransformer%E4%B8%8E%E5%9B%BE%E7%89%87%E6%8F%8F%E8%BF%B0/" class="md-nav__link">
        06.Transformer与图片描述
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B07%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%8C%E5%9B%BE%E5%83%8F%E6%AC%BA%E8%AF%88%E5%92%8CGAN/" class="md-nav__link">
        07.模型可视化，图像欺诈和GAN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Stanford-CS231N-Assignment%E6%9C%AD%E8%AE%B08%EF%BC%9A%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AF%BE%E7%A8%8B%E6%80%BB%E7%BB%93/" class="md-nav__link">
        08.自监督学习与课程总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../CS224W/">CS224W-图机器学习与图神经网络</a>
          
            <label for="__nav_2_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="CS224W-图机器学习与图神经网络" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          CS224W-图机器学习与图神经网络
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A001/" class="md-nav__link">
        01.导论，传统的图学习方法
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A002/" class="md-nav__link">
        02.节点嵌入和PageRank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A003/" class="md-nav__link">
        03.消息传递机制
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A004/" class="md-nav__link">
        04.图神经网络基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A005/" class="md-nav__link">
        05.图神经网络的训练和应用，表示能力分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A006/" class="md-nav__link">
        06.知识图谱，知识图谱推理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A007/" class="md-nav__link">
        07.频繁子图挖掘
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A008/" class="md-nav__link">
        08.社区检测
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A009/" class="md-nav__link">
        09.图生成模型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../CS224W/CS224W%EF%BC%9A%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A010/" class="md-nav__link">
        10.图神经网络前沿话题
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../%E6%9D%82%E8%B0%88%E4%B8%8E%E6%80%BB%E7%BB%93/">杂谈与总结</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="杂谈与总结" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          杂谈与总结
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../%E6%9D%82%E8%B0%88%E4%B8%8E%E6%80%BB%E7%BB%93/2022%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/" class="md-nav__link">
        2022年度总结
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#卷基层convolution-layer" class="md-nav__link">
    卷基层Convolution Layer
  </a>
  
    <nav class="md-nav" aria-label="卷基层Convolution Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#什么是卷积层" class="md-nav__link">
    什么是卷积层？
  </a>
  
    <nav class="md-nav" aria-label="什么是卷积层？">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#卷积的计算公式" class="md-nav__link">
    卷积的计算公式
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#步长stride" class="md-nav__link">
    步长Stride
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#接受域receptive-field" class="md-nav__link">
    接受域Receptive Field
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#padding操作" class="md-nav__link">
    Padding操作
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积层带来的突破" class="md-nav__link">
    卷积层带来的突破
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积层的代码实现" class="md-nav__link">
    卷积层的代码实现
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积层的反向传播" class="md-nav__link">
    卷积层的反向传播
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#卷积的实际效果" class="md-nav__link">
    卷积的实际效果
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#池化层pooling-layer" class="md-nav__link">
    池化层Pooling Layer
  </a>
  
    <nav class="md-nav" aria-label="池化层Pooling Layer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#什么是池化层" class="md-nav__link">
    什么是池化层
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#池化层的前向传播" class="md-nav__link">
    池化层的前向传播
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#池化层的反向传播" class="md-nav__link">
    池化层的反向传播
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#三层cnn" class="md-nav__link">
    三层CNN
  </a>
  
    <nav class="md-nav" aria-label="三层CNN">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#三层cnn的架构" class="md-nav__link">
    三层CNN的架构
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#代码实现" class="md-nav__link">
    代码实现
  </a>
  
    <nav class="md-nav" aria-label="代码实现">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#初始化" class="md-nav__link">
    初始化
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#前向传播和反向传播" class="md-nav__link">
    前向传播和反向传播
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#三层cnn的pytorch实现" class="md-nav__link">
    三层CNN的Pytorch实现
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  



<h1 id="stanford-cs231n-assignment札记4卷积神经网络cnn">Stanford-CS231N-Assignment札记4：卷积神经网络CNN<a class="headerlink" href="#stanford-cs231n-assignment札记4卷积神经网络cnn" title="Permanent link">&para;</a></h1>
<blockquote>
<p>Stanford2021年春季课程CS231N:Convolutional Neural Networks for Visual Recognition的一些作业笔记，这门课的作业围绕视觉相关的任务，需要从底层手动实现一大批经典机器学习算法和神经网络模型，本文是作业的第四部分，包含了卷积神经网络以及其关键组件的实现(卷积层，池化层)</p>
</blockquote>
<h2 id="卷基层convolution-layer">卷基层Convolution Layer<a class="headerlink" href="#卷基层convolution-layer" title="Permanent link">&para;</a></h2>
<h3 id="什么是卷积层">什么是卷积层？<a class="headerlink" href="#什么是卷积层" title="Permanent link">&para;</a></h3>
<h4 id="卷积的计算公式">卷积的计算公式<a class="headerlink" href="#卷积的计算公式" title="Permanent link">&para;</a></h4>
<ul>
<li>卷积层是CNN中最核心的一个idea，通过卷积核(实质上就是一种滤波器)对输入的特征进行卷积运算，如果输入的数据是语音，那么数据是一维的，就可以进行一维卷积，如果输入的是矩阵，那么就可以进行二维的卷积，而CNN一般是用来处理图像的，图像是一种三维的数据(因为图像有颜色通道，每个通道上是一个二维矩阵，常见的RGB图像就是3颜色通道)，就需要用三维的卷积核对输入进行卷积操作。</li>
<li>假设一个卷积核的大小是<span class="arithmatex">\(2M\times 2N\)</span>，那么 卷积的计算公式如下：</li>
</ul>
<div class="arithmatex">\[
s\left[i,j\right]=(x*w)[i,j]=\sum_{m=-M}^M\sum_{n=-N}^Nx[i+m,j+n]w[m,n]
\]</div>
<p><img alt="image-20211107214343564" src="../static/image-20211107214343564.png" /></p>
<ul>
<li>比如上面这张图中，一个大小为32x32x3的图像使用一个5x5x3的卷积核进行卷积之后得到的就是28x28x3的新图像，我们称卷积之后得到的新的图像称为feature map</li>
</ul>
<h4 id="步长stride">步长Stride<a class="headerlink" href="#步长stride" title="Permanent link">&para;</a></h4>
<ul>
<li>卷积核的移动存在一个步长(stride)，卷积核移动的步长小于卷积核的边长时，变会出现卷积核与原始输入矩阵作用范围在区域上的**重叠**，卷积核移动的步长与卷积核的边长相一致时，不会出现重叠现象</li>
<li>因此卷积操作需要设定一个步长，步长也会决定得到的新的feature map的大小</li>
</ul>
<h4 id="接受域receptive-field">接受域Receptive Field<a class="headerlink" href="#接受域receptive-field" title="Permanent link">&para;</a></h4>
<ul>
<li>卷积核可以覆盖到的局部特征区域，比如一个3x3的卷积核可以包含一个3x3区域内的信息，那么其接收域就是3x3，随着层数的加深，接受域也在变大。大的步长也使得接受域的增大速度变快</li>
</ul>
<h4 id="padding操作">Padding操作<a class="headerlink" href="#padding操作" title="Permanent link">&para;</a></h4>
<ul>
<li>我们发现按照卷积的运算方式，处于图像的边缘处的像素点可能没有对应位置的像素点来计算其卷积(也就是说用上面的公式进行计算的时候，下标溢出了)，padding操作可以解决这一问题</li>
</ul>
<h4 id="卷积层带来的突破">卷积层带来的突破<a class="headerlink" href="#卷积层带来的突破" title="Permanent link">&para;</a></h4>
<p>《深度学习（花书）》中提出卷积这一操作的引入带来的突破有：
- 稀疏交互Sparse interactions
  - 传统的神经网络使用矩阵乘法来建立输入输出的连接关系，参数矩阵中的每一个参数都代表了输入和输出的交互关系，而卷积层的运算因为卷积核的大小一般是远小于图像的大小的，因此只需要较少的计算量就可以提取关键的图像信息(比如图像的边缘)
  - 传统情况下，如果有m维度的输入和n维度的输出，那么参数矩阵就需要<span class="arithmatex">\(m\times n\)</span>的规模，这种时候其实就是一种输入到输出的全连接，<strong>通过卷积运算，减少了从输入到输出的连接数量</strong>
- 参数共享Parameter Sharing
  - 参数共享是说可以在一个模型的多个函数中使用一样的参数，传统的神经网络中，当计算了一层的输入的时候，权重矩阵的每一个元素只能使用一次，也就是说网络中有绑定的权重
  - 在CNN中，核的每个元素都作用在输入的每一个位置上，卷积运算的参数共享保证了只需要学习一个参数集合而不是对于每一个位置都需要学习一个单独的参数集合。
- 等变表示Equivariant Representation
  - 如果一个函数满足输入改变，输出也以同样的方式改变，那么就可以称这个函数是等变的，如果对于函数f和g有<span class="arithmatex">\(f(g(x))=g(f(x))\)</span>那么就称f和g具有等变性。
  - 对于卷积而言，参数共享的特殊形式是的神经网络层具有对平移操作等变的性质，这里可以令g为平移函数，那么g就可以表示图像函数的变换函数。
  - 简而言之这一性质表明，对于图像中一些需要提取的特征，<strong>即使图像发生了平移，这个特征依然存在只是发生了对应的平移而已，仍然可以用一样的方式提取出来</strong>。在处理时间序列数据的时候，这个性质意味着卷积可以得到一个由输入中出现不同特征的时刻所组成的时间轴。</p>
<h3 id="卷积层的代码实现">卷积层的代码实现<a class="headerlink" href="#卷积层的代码实现" title="Permanent link">&para;</a></h3>
<p>下面使用一个函数<code>conv_forward_naive</code>来实现一种非常naive的卷积层计算方法，事实上就是用多重循环将卷积的结果一个个算出来。注意这里的卷积运算有个bias，上面的公式没有提到</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">conv_forward_naive</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">conv_param</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">conv_param</span><span class="p">[</span><span class="s2">&quot;stride&quot;</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">conv_param</span><span class="p">[</span><span class="s2">&quot;pad&quot;</span><span class="p">]</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">HH</span><span class="p">,</span> <span class="n">WW</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">new_H</span><span class="p">,</span> <span class="n">new_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span> <span class="o">-</span> <span class="n">HH</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span> <span class="o">-</span> <span class="n">WW</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">new_H</span><span class="p">,</span> <span class="n">new_W</span><span class="p">))</span>
    <span class="c1"># 对x进行zero-pad操作，得到一个扩充后的矩阵，这里只对x的第三四个维度(也就是像素值所在的维度)进行扩充</span>
    <span class="n">x_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">),</span> <span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">)),</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">new_x</span> <span class="o">=</span> <span class="n">x_pad</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">F</span><span class="p">):</span>
            <span class="c1"># 得到卷积核</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">f</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_H</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_W</span><span class="p">):</span>
                    <span class="c1"># 取出对应的卷积区域，并进行计算</span>
                    <span class="n">conv_zone</span> <span class="o">=</span> <span class="n">new_x</span><span class="p">[:,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">HH</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">WW</span><span class="p">]</span>
                    <span class="n">conv_res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">conv_zone</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">f</span><span class="p">]</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_res</span>
    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">conv_param</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div>
<p>当然这种实现方式是非常naive的，只能用来测试自己是否理解了卷积操作，真的用来构建神经网络的话计算效率会非常低，CS231N的assignment2中给出了cpython加速的卷积操作的向量化实现，可以较大地提高计算的效率。</p>
<h3 id="卷积层的反向传播">卷积层的反向传播<a class="headerlink" href="#卷积层的反向传播" title="Permanent link">&para;</a></h3>
<p>卷积的反向传播比较简单，我们假设卷积核的大小是<span class="arithmatex">\(2M\times 2N\)</span>，那么对于卷积后得到的feature map的一个像素点<span class="arithmatex">\(s_{ij}\)</span>，我们根据上面的卷积公式可以得到：
$$
\frac{\partial s_{ij}}{\partial x_{i+m,j+n}}=w_{mn}，m\in [-M,M],n\in [-N,N]
$$</p>
<div class="arithmatex">\[
\frac{\partial s_{ij}}{\partial w_{mn}}=x_{i+m,j+n},，m\in [-M,M],n\in [-N,N]
\]</div>
<div class="arithmatex">\[
\frac{\partial s_{ij}}{\partial b}=1^{2M\times 2N}
\]</div>
<p>因此反向传播求dx的时候只要把feature map的每个像素点进行遍历，把权重加到原位置的点上就可以，并且还要乘上传递到这一层的梯度dout，具体的代码实现如下：</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">conv_backward_naive</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
    <span class="n">dx</span><span class="p">,</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">Nonex</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">conv_param</span> <span class="o">=</span> <span class="n">cache</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">conv_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;stride&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">conv_param</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;pad&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># 定义好梯度的大小</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">F</span><span class="p">,</span> <span class="n">C_prime</span><span class="p">,</span> <span class="n">HH</span><span class="p">,</span> <span class="n">WW</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">H_prime</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span> <span class="o">-</span> <span class="n">HH</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">W_prime</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pad</span> <span class="o">-</span> <span class="n">WW</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="c1"># 进行padding操作</span>
    <span class="n">dx_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">),</span> <span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">)),</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">x_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">),</span> <span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">)),</span> <span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">x_i</span> <span class="o">=</span> <span class="n">x_pad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">F</span><span class="p">):</span>
            <span class="n">w_j</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">h_now</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">H_prime</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">w_now</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">W_prime</span><span class="p">):</span>
                    <span class="c1"># 在原来的对应像素位置上，按照权重加上梯度</span>
                    <span class="n">db</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dout</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h_now</span><span class="p">,</span> <span class="n">w_now</span><span class="p">]</span>
                    <span class="n">dx_pad</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="n">h_now</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span><span class="n">h_now</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">HH</span><span class="p">,</span> <span class="n">w_now</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span><span class="n">w_now</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">WW</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dout</span><span class="p">[</span>
                                                                                                                <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h_now</span><span class="p">,</span> <span class="n">w_now</span><span class="p">]</span> <span class="o">*</span> <span class="n">w_j</span>
                    <span class="n">dw</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dout</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">h_now</span><span class="p">,</span> <span class="n">w_now</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_i</span><span class="p">[:,</span> <span class="n">h_now</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span><span class="n">h_now</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">HH</span><span class="p">,</span>
                                                        <span class="n">w_now</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span><span class="n">w_now</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">WW</span><span class="p">]</span>

    <span class="n">dx</span> <span class="o">=</span> <span class="n">dx_pad</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">,</span> <span class="n">pad</span><span class="p">:</span><span class="o">-</span><span class="n">pad</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">dx</span><span class="p">,</span> <span class="n">dw</span><span class="p">,</span> <span class="n">db</span>
</code></pre></div>
<h3 id="卷积的实际效果">卷积的实际效果<a class="headerlink" href="#卷积的实际效果" title="Permanent link">&para;</a></h3>
<p>作业中为了展示卷积的效果，使用了两张猫狗图片进行卷积操作，我们得到的结果如下：</p>
<p><img alt="image-20211107214845526" src="../static/image-20211107214845526.png" /></p>
<ul>
<li>从这个结果中可以看出，卷积操作对图片中一些边缘和轮廓的特征进行了增强，而淡化了其他的一些特征，这些边缘和轮廓的特征，正是我们需要提取的图片特征</li>
</ul>
<h2 id="池化层pooling-layer">池化层Pooling Layer<a class="headerlink" href="#池化层pooling-layer" title="Permanent link">&para;</a></h2>
<h3 id="什么是池化层">什么是池化层<a class="headerlink" href="#什么是池化层" title="Permanent link">&para;</a></h3>
<ul>
<li>当我们发现了一个特征之后，这个特征相对于其他特征的位置相比于这个特征的值而言更为重要，很明显的一个例子就是计算机视觉中的目标检测任务，我们要检测的目标所处周围环境的特点更能帮助我们检测出真的目标，这就是池化层的idea的来源，池化层是CNN架构中提出的另一种特殊层，起到了**降采样**的作用。</li>
<li>池化就是通过一种非线性的变换，对特征进行进一步的**抽象和降维**，常见的有最大池化，平均池化等等，就是按照池化窗口的大小将矩阵分成若干个区域，在每个区域中进行池化操作(求最大，均值等等)，生成一个维度更小的feature map，同时池化层也可以起到防止过拟合的作用。</li>
<li>池化层同样也有长宽和步长等参数</li>
</ul>
<h3 id="池化层的前向传播">池化层的前向传播<a class="headerlink" href="#池化层的前向传播" title="Permanent link">&para;</a></h3>
<ul>
<li>池化层的前向传播也是通过一系列for循环进行对应的池化操作，这里我们以最大池化为例，实现了函数<code>max_pool_forward_naive</code> </li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">max_pool_forward_naive</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_param</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">pool_param</span><span class="p">[</span><span class="s2">&quot;pool_height&quot;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s2">&quot;pool_width&quot;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
    <span class="n">new_H</span><span class="p">,</span> <span class="n">new_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">new_H</span><span class="p">,</span> <span class="n">new_W</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_H</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_W</span><span class="p">):</span>
                    <span class="c1"># 按块取出最大值即可</span>
                    <span class="n">max_pix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">w</span><span class="p">])</span>
                    <span class="n">out</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_pix</span>
    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pool_param</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div>
<h3 id="池化层的反向传播">池化层的反向传播<a class="headerlink" href="#池化层的反向传播" title="Permanent link">&para;</a></h3>
<ul>
<li>反向传播涉及到池化层的求导问题，这里我们使用的是最大池化，因此也就是需要对max函数进行求导，而在ReLU层我们已经知道max函数的导数是分段的，小于0的部分是0，大于0的部分是1，而在池化层中也是一样的道理，对于进行池化操作的每个区域，最大的那个位置的梯度就是池化层向后传递的梯度，而其他地方都是0，我们可以在cache中记录原本矩阵的信息，并在池化层的反向传播过程中使用。</li>
<li>当然如果一个区域内有多个点的都是最大值的时候，可以把梯度进行平均分，这一过程在<code>max_pool_backward_naive</code>中通过一个<code>mask</code>矩阵来实现：</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">max_pool_backward_naive</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">pool_param</span> <span class="o">=</span> <span class="n">cache</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">pool_param</span><span class="p">[</span><span class="s2">&quot;pool_height&quot;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s2">&quot;pool_width&quot;</span><span class="p">],</span> <span class="n">pool_param</span><span class="p">[</span><span class="s1">&#39;stride&#39;</span><span class="p">]</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">new_H</span><span class="p">,</span> <span class="n">new_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">H</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_H</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">new_W</span><span class="p">):</span>
                    <span class="n">pool</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">w</span><span class="p">]</span>
                    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">pool</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                    <span class="n">mask</span><span class="p">[</span><span class="n">pool</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">pool</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
                    <span class="n">mask</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
                    <span class="n">dx</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">h</span><span class="p">,</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span><span class="p">:</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">+</span> <span class="n">w</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">dout</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">dx</span>
</code></pre></div>
<h2 id="三层cnn">三层CNN<a class="headerlink" href="#三层cnn" title="Permanent link">&para;</a></h2>
<h3 id="三层cnn的架构">三层CNN的架构<a class="headerlink" href="#三层cnn的架构" title="Permanent link">&para;</a></h3>
<p>写了这么久我们终于来到了手写CNN的环节，当然我们前面写的一些东西比较naive，不堪大用，只能用于理解和学习CNN中各个层的作用，因此CS231N的assignment2为我们提供了一些写好的层，将原来的一些层进行了组合，比如<code>affine_relu_forward</code>，<code>conv_relu_forward</code>和<code>conv_bn_relu_forward</code>，其实也只是在我们写好的layers上面封装了一层函数，将全连接层+ReLU，卷积层+ReLU组合成了完整的一个层</p>
<p>CNN通常来说是这样的架构：</p>
<p><img alt="image-20211107214651193" src="../static/image-20211107214651193.png" /></p>
<p>而我们需要实现的三层CNN的架构就是：<code>conv - relu - 2x2 max pool - affine - relu - affine - softmax</code> 和上面的图基本一致。</p>
<h3 id="代码实现">代码实现<a class="headerlink" href="#代码实现" title="Permanent link">&para;</a></h3>
<h4 id="初始化">初始化<a class="headerlink" href="#初始化" title="Permanent link">&para;</a></h4>
<ul>
<li>
<p>我们定义了一个类<code>ThreeLayerConvNet</code>，并需要实现类的初始化和前向反向传播</p>
</li>
<li>
<p>初始化和前面的全连接神经网络基本一致，这里需要注意的就是，我们需要实现的三层神经网络架构中的参数主要有：</p>
</li>
<li>卷积层的卷积核W1和偏差b1</li>
<li>第一个全连接层的参数W2和b2</li>
<li>第二个全连接层的参数W3和b3</li>
<li>以上这些参数都要按照正态分布的规则进行随机初始化，这一部分代码比较简单，就不放出来了。</li>
</ul>
<h4 id="前向传播和反向传播">前向传播和反向传播<a class="headerlink" href="#前向传播和反向传播" title="Permanent link">&para;</a></h4>
<ul>
<li>我们需要在loss函数中实现前向传播和反向传播，并求出所有参数的梯度和总的损失函数</li>
<li>前向传播的过程比较简单，就是用现成的api一层层计算下去：</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluate loss and gradient for the three-layer convolutional network.</span>
<span class="sd">        Input / output: Same API as TwoLayerNet in fc_net.py.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;W1&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;b1&quot;</span><span class="p">]</span>
        <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;W2&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;b2&quot;</span><span class="p">]</span>
        <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;W3&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;b3&quot;</span><span class="p">]</span>

        <span class="c1"># pass conv_param to the forward pass for the convolutional layer</span>
        <span class="c1"># Padding and stride chosen to preserve the input spatial size</span>
        <span class="n">filter_size</span> <span class="o">=</span> <span class="n">W1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">conv_param</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;pad&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">filter_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">}</span>

        <span class="c1"># pass pool_param to the forward pass for the max-pooling layer</span>
        <span class="n">pool_param</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;pool_height&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;pool_width&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;stride&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># 逐层实现反向传播</span>
        <span class="n">out1</span><span class="p">,</span> <span class="n">cache1</span> <span class="o">=</span> <span class="n">conv_relu_pool_forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">b1</span><span class="p">,</span> <span class="n">conv_param</span><span class="p">,</span> <span class="n">pool_param</span><span class="p">)</span>
        <span class="n">out2</span><span class="p">,</span> <span class="n">cache2</span> <span class="o">=</span> <span class="n">affine_relu_forward</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">W2</span><span class="p">,</span> <span class="n">b2</span><span class="p">)</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">cache3</span> <span class="o">=</span> <span class="n">affine_forward</span><span class="p">(</span><span class="n">out2</span><span class="p">,</span> <span class="n">W3</span><span class="p">,</span> <span class="n">b3</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">scores</span>
</code></pre></div>
<ul>
<li>然后反向传播就是用已经写好的单层反向传播组合起来，同时也可以算出loss函数，注意最后要加上正则项</li>
</ul>
<div class="highlight"><pre><span></span><code>                 <span class="n">loss</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="p">{}</span>

        <span class="n">loss</span><span class="p">,</span> <span class="n">dout</span> <span class="o">=</span> <span class="n">softmax_loss</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">dout3</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W3&#39;</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;b3&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">affine_backward</span><span class="p">(</span><span class="n">dout</span><span class="p">,</span> <span class="n">cache3</span><span class="p">)</span>
        <span class="n">dout2</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;b2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">affine_relu_backward</span><span class="p">(</span><span class="n">dout3</span><span class="p">,</span> <span class="n">cache2</span><span class="p">)</span>
        <span class="n">dout1</span><span class="p">,</span> <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">],</span> <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;b1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_relu_pool_backward</span><span class="p">(</span><span class="n">dout2</span><span class="p">,</span> <span class="n">cache1</span><span class="p">)</span>
        <span class="c1"># 加上正则项</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W1</span> <span class="o">*</span> <span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W2</span> <span class="o">*</span> <span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">W3</span> <span class="o">*</span> <span class="n">W3</span><span class="p">))</span>
        <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W3&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">*</span> <span class="n">W3</span>
        <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W2&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">*</span> <span class="n">W2</span>
        <span class="n">grads</span><span class="p">[</span><span class="s1">&#39;W1&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reg</span> <span class="o">*</span> <span class="n">W1</span>
</code></pre></div>
<ul>
<li>最后这个自己搭建的简单三层神经网络**在部分CIFAR数据集上**的表现如下图所示，可以看到在训练集上的表现非常不错，但是在测试集上的表现比较糟糕，原因也很简单，就是因为神经网络训练过程中过拟合了，如果考虑使用标准化层和DropOut可能表现效果会更好一点</li>
</ul>
<p><img alt="image-20211107214722089" src="../static/image-20211107214722089.png" /></p>
<p>而当我们在整个CIFAR数据集上进行训练的时候，最后得到的三层CNN在训练集和验证集上的精度分别是0.476和0.499</p>
<h3 id="三层cnn的pytorch实现">三层CNN的Pytorch实现<a class="headerlink" href="#三层cnn的pytorch实现" title="Permanent link">&para;</a></h3>
<ul>
<li>这部分作业的最后也要求我们用Pytorch实现一个架构和上面相同的CNN，而Pytorch框架有自动求梯度的功能，相比之下搭建神经网络就简单了很多。</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ThreeLayerConvNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channel</span><span class="p">,</span> <span class="n">channel_1</span><span class="p">,</span> <span class="n">channel_2</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channel</span><span class="p">,</span> <span class="n">channel_1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channel_1</span><span class="p">,</span> <span class="n">channel_2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channel_2</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">Nonex</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># 这是一个另外定义的将张量压缩成一维的函数</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">scores</span>
</code></pre></div>
<ul>
<li>我们用这样几行代码就做好了一个简单的三层神经网络，使用Pytorch的<code>nn.Module API</code>搭建神经网络的时候只需要继承<code>nn.Module</code>类，并在init函数中定义好所需要的层，在forward函数中定义神经网络的计算过程就可以了</li>
<li>模型的训练也很简单，只需要定义优化器和编写简单的每个epoch代码，Pytorch就会自动完成求梯度和反向传播的过程。</li>
</ul>
<p><span id="busuanzi_container_page_pv">本文总阅读量<span id="busuanzi_value_page_pv"></span>次</span></p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class="timeago" datetime="2023-01-23T10:40:25+00:00" locale="en"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-01-23</span>
      
        <br>
        创建日期:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-timeago"><span class="timeago" datetime="2023-01-23T05:18:04+00:00" locale="en"></span></span><span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-01-23</span>
      
    
  </small>
</div>




<div id="__comments">
    
    <script src="https://giscus.app/client.js"
        data-repo="Zhang-Each/My-CS-Notebook"
        data-repo-id="R_kgDOI0dr4w"
        data-category="General"
        data-category-id="DIC_kwDOI0dr484CTvIK"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="bottom"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
        </script>
    <h3>颜色主题调整</h3>
    <div class="tx-switch">
    <button class="button1" data-md-color-primary="red" style="background-color:red">red</button>
    <button class="button1" data-md-color-primary="pink" style="background-color:pink;color:black">pink</button>
    <button class="button1" data-md-color-primary="purple" style="background-color:purple">purple</button>
    <button class="button1" data-md-color-primary="indigo" style="background-color:indigo">indigo</button>
    <button class="button1" data-md-color-primary="blue" style="background-color:blue">blue</button>
    <button class="button1" data-md-color-primary="cyan" style="background-color:cyan;color:black">cyan</button>
    <button class="button1" data-md-color-primary="teal" style="background-color:teal">teal</button>
    <button class="button1" data-md-color-primary="green" style="background-color:green">green</button>
    <button class="button1" data-md-color-primary="lime" style="background-color:lime;color:black">lime</button>
    <button class="button1" data-md-color-primary="orange" style="background-color:orange;color:black">orange</button>
    <button class="button1" data-md-color-primary="brown" style="background-color:brown;border-radius=3px">brown</button>
    <button class="button1" data-md-color-primary="grey" style="background-color:grey">grey</button>
    <button class="button1" data-md-color-primary="black" style="background-color:black">black</button>
    <button class="button1" data-md-color-primary="white" style="background-color:white;color:black">white</button>
    </div>
    
    <script>
    var buttons = document.querySelectorAll("button[data-md-color-primary]")
    buttons.forEach(function(button) {
            button.addEventListener("click", function() {
            var attr = this.getAttribute("data-md-color-primary")
            document.body.setAttribute("data-md-color-primary", attr)
            localStorage.setItem("data-md-color-primary",attr);
            })
    })
    </script>
    
    <h2 ><!-- 评论 -->评论区~</h2>
    
    有用的话请给我个star或者follow我的账号!! 非常感谢!!
    
    </br>
    
    快来跟我聊天~
    
    </div>
    
    <script src="https://giscus.app/client.js"
        data-repo="Zhang-Each/Notebook-Comments"
        data-repo-id="R_kgDOI0dlNg"
        data-category="General"
        data-category-id="DIC_kwDOI0dlNs4CTvH-"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="1"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="zh-CN"
        data-loading="lazy"
        crossorigin="anonymous"
        async>
    </script>
    
    <!-- Synchronize Giscus theme with palette -->
    <script>
    var giscus = document.querySelector("script[src*=giscus]")
    
    /* Set palette on initial load */
    // var palette = __md_get("__palette")
    // if (palette && typeof palette.color === "object") {
    //     var theme = palette.color.scheme === "slate" ? "dark" : "light"
    //     giscus.setAttribute("data-theme", theme) 
    // }
    
    /* Register event handlers after documented loaded */
    // document.addEventListener("DOMContentLoaded", function() {
    //     var ref = document.querySelector("[data-md-component=palette]")
    //     ref.addEventListener("change", function() {
    //     var palette = __md_get("__palette")
    //     if (palette && typeof palette.color === "object") {
    //         var theme = palette.color.scheme === "slate" ? "dark" : "light"
    
    //         /* Instruct Giscus to change theme */
    //         var frame = document.querySelector(".giscus-frame")
    //         frame.contentWindow.postMessage(
    //         { giscus: { setConfig: { theme } } },
    //         "https://giscus.app"
    //         )
    //     }
    //     })
    // })
    </script>
                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      本页面的全部内容在 <a href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh">CC BY-SA 4.0</a> 和 <a href="https://github.com/zTrix/sata-license">SATA</a> 协议之条款下提供，附加条款亦可能应用。<br /><span id="busuanzi_container_site_uv">本站访客总人数<span id="busuanzi_value_site_uv"></span>人次，</span><span id="busuanzi_container_site_pv">本站总访问次数<span id="busuanzi_value_site_pv"></span>次。</span>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "content.code.annotate", "navigation.tracking", "navigation.indexes", "navigation.top", "toc.follow"], "search": "../../assets/javascripts/workers/search.e5c33ebb.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.51d95adb.min.js"></script>
      
        <script src="../../js/timeago.min.js"></script>
      
        <script src="../../js/timeago_mkdocs_material.js"></script>
      
        <script src="../../from_oi_wiki/js/extra.js"></script>
      
        <script src="../../js/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../../js/tablesort.js"></script>
      
        <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
      
    
  </body>
</html>